---
title: "Regresion Logistica"
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, error = FALSE)

# Bibliotecas
library(ggplot2)
library(dplyr)
library(knitr)
library(kableExtra)
```

```{r administrativas, include = FALSE}
source("../R/Utils.R")
```

# Cargar los datos

Cargamos los datos que se usaron durante el análisis descriptivo de los datos y mostramos las variables a usar.

```{r}
datos_it0 <- read.csv("../data/bd_trabajo.csv")
names(datos_it0)
```

No vamos a mostrar las medidas resumenes o los gráficos de todas las variables ya que lo hicimos durante el análisis descriptivo. A lo largo del trabajo solo mostraremos los gráficos pertinentes.

# Regresion Logística

En esta regresión vamos a utilizar como variable respuesta a **diagnostico**, usando las variables **d1**, **d2**, **d3**, **d4**, **d5** y **edad**. Para trabajar vamos a quedarnos únicamente con estas variables en el dataset.

```{r}
datos_it1 <- datos_it0 %>% 
  select(diagnostico, d1, d2, d3, d4, d5, edad)
names(datos_it1)
```

Comenzamos realizando el modelo 0, donde se incluyen todas las variables posibles

```{r, collapse = TRUE}
modelo_it0 <- glm(diagnostico ~ ., data = datos_it1, family = "binomial")
summary(modelo_it0)

r2 <- calcular_pseudo_R2(modelo_it0)
r2
```
Observamos que las variables **d1**, **d2** y **edad** resultan significativas, pero **d3**, **d4** y **d5** no.

Además, armaremos una tabla donde se especificara el AIC, R2 y alguna de observación de cada modelo armado, a manera comparación.

```{r}
tabla_resumen_modelos <- data.frame(Nombre = "modelo_it0", 
                                    AIC = modelo_it0$aic,
                                    R2 = r2[1],
                                    Observacion = "Todas las variables",
                                    row.names = NULL)
rm(r2)
```

Usamos la función step() para seleccionar aquellas variables más importantes.

```{r}
step(modelo_it0, direction = "both")
```

A partir del resultado creamos el primer modelo

```{r, collapse = TRUE}
modelo_it1 <- glm(formula = diagnostico ~ d1 + d2 + edad, family = "binomial", 
    data = datos_it1)
summary(modelo_it1)

r2 <- calcular_pseudo_R2(modelo_it1)
r2
```
Todas las variables resultan significativas. El AIC es de `r round(modelo_it1$aic, 2)`, que es levemente mejor al modelo 0. De aquí notamos que:

* Por cada incremento de una unidad en **d1**, los odds de tener un diagnóstico positivo se incrementan en `r  round(exp(.086348) * 100 - 100, 2)`%, manteniendo el resto de variables constantes.
* Por cada incremento de una unidad de **d2**, los odss de tener un diagnóstico positivo se reducen en `r round(100 - exp(-.004163) * 100, 2)`%, manteniendo el resto de variables constantes.
* Por cada incremento de un año en la **edad**, los odds de tener un diagnóstico positivo se incrementan en `r  round(exp(.104027) * 100 - 100, 2)`%, manteniendo el resto de variables constantes.

```{r}
tabla_resumen_modelos <- tabla_resumen_modelos %>% 
  add_row(Nombre = "modeo_it1", AIC = modelo_it1$aic, R2 = r2[1], Observacion = "Primer modelo con selección de variables")
rm(r2)
```

## Puntos Influyentes

Empezamos buscando los puntos influyentes con la distancia_cook

```{r}
puntos_influyentes <- data.frame(d_cook = cooks.distance(modelo_it1)) %>% arrange(-d_cook)
head(puntos_influyentes, n = 15)
```

En general, las distancias son menores a uno por lo que no se consideran influyentes. Sin embargo, analizsamos la observación nro 368 por se la que presta una distancia de cook mucho mayor al resto.

```{r}
datos_it1[368,]
```

Esta observación presenta un valor de d2 muy bajo. Vamos a calcular los hatvalues para saber si es un outlier

```{r}
puntos_outliers <- data.frame(v_hat = hatvalues(modelo_it1)) %>% arrange(-v_hat)
head(puntos_outliers, n = 15)
```

Como la observación tiene un hatvalue de 0.02414641, que es mayor a `r 2 * 3 / nrow(datos_it1)` lo consideramos atípico. 

```{r}
datos_it2 <- datos_it1[-368,]
```

Volvemos a realizar los modelos para observar si conseguimos una mejoría excluyendo esta observación.

```{r, collapse = TRUE}
modelo_it2 <- glm(diagnostico ~ ., data = datos_it2, family = "binomial")
summary(modelo_it2)

r2 <- calcular_pseudo_R2(modelo_it2)
r2
```

Para este modelo resultan **d1**, **d2** y **edad** significativas.

```{r}
tabla_resumen_modelos <- tabla_resumen_modelos %>% 
  add_row(Nombre = "modelo_it2", AIC = modelo_it2$aic, R2 = r2[1], Observacion = "Modelo todas variables, excluimos observacion 368")
rm(r2)
```

Ahora seleccionamos variables con stepwise

```{r}
step(modelo_it2, direction = "both")
```
Creamos el modelo con los resultados

```{r}
modelo_it3 <- glm(formula = diagnostico ~ d1 + d2 + edad, family = "binomial", data = datos_it2)
summary(modelo_it3)

r2 <- calcular_pseudo_R2(modelo_it3)
r2
```
Se obtiene que todas las variables son significativas. Se observa un AIC de `r round(modelo_it3$aic, 2)`, que es el mejor obtenido hasta ahora. 

  * Por cada incremento de una unidad en **d1**, los odds de tener un diagnóstico postivo incrementan en `r round(exp(0.085258) * 100 - 100, 2)`%, manteniendo el resto de variables constantes.
  * Por cada incremento de una unidad en **d2**, los odds de tener un diagnóstico positivo se reducen en `r round(100 - exp(-0.004821) * 100, 2)`%, manteniendo el resto de variables constantes.
  * Por cada incremento de un año en la **edad**, los odds de tener un diagnóstico positivo se incrementan en `r round(exp(0.104276) * 100 - 100, 2)`% manteniendo el resto de variables constantes.
  
  

