---
title: "Regresion Logistica"
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, error = FALSE)

# Bibliotecas
library(ggplot2)
library(dplyr)
library(knitr)
library(kableExtra)
library(ggcorrplot)
library(car)
```

```{r administrativas, include = FALSE}
source("../R/Utils.R")
```

# Cargar los datos

Cargamos los datos que se usaron durante el análisis descriptivo de los datos y mostramos las variables a usar.

```{r}
datos_it0 <- read.csv("../data/bd_trabajo.csv")
names(datos_it0)
```

No vamos a mostrar las medidas resumenes o los gráficos de todas las variables ya que lo hicimos durante el análisis descriptivo.


# Regresion Logística

En esta regresión vamos a utilizar como variable respuesta a **diagnostico**, usando las variables **d1**, **d2**, **d3**, **d4**, **d5** y **edad**. Para trabajar vamos a quedarnos únicamente con estas variables en el dataset.

```{r}
datos_it1 <- datos_it0 %>% 
  select(diagnostico, d1, d2, d3, d4, d5, edad)
names(datos_it1)
```

## ¿Colinealidad/Multicolinealidad?

En realidad no es 100% necesario hacer esto, pero lo hacemos igual para llegar a detectarlo antes de que cause problemas.

Empezamos realizando la matriz de correlación de las varaibles para descartar la colinealidad.

```{r}
datos_it1 %>% 
  select(-diagnostico) %>% 
  cor() %>% 
  ggcorrplot(lab = TRUE)
```

No se observa ningun coeficiente de correlación mayor/menor a .5/-.5. Ahora, buscamos multicolinealidad usando el VIF. Para esto creamos una regresión lineal múltiple para verficiar si existe multicolinealidad entre todas las variables predictoras.

```{r}
vif(lm(d1 ~ edad + d2 + d3 + d4 + d5, data = datos_it1))
```
Se descarta multicolinealidad porque ningún VIF supera el valor de 10.

## Empezando con los modelos

Comenzamos realizando el modelo 0, donde se incluyen todas las variables posibles

```{r, collapse = TRUE}
modelo_it0 <- glm(diagnostico ~ ., data = datos_it1, family = "binomial")
summary(modelo_it0)

r2 <- calcular_pseudo_R2(modelo_it0)
r2
```
Observamos que las variables **d1**, **d2** y **edad** resultan significativas, pero **d3**, **d4** y **d5** no.

Además, armaremos una tabla donde se especificara el AIC, R2 y alguna de observación de cada modelo armado, a manera comparación.

```{r}
tabla_resumen_modelos <- data.frame(Nombre = "modelo_it0", 
                                    AIC = modelo_it0$aic,
                                    R2 = r2[1],
                                    Observacion = "Todas las variables",
                                    row.names = NULL)
rm(r2)
```

Usamos la función step() para seleccionar aquellas variables más importantes.

```{r}
step(modelo_it0, direction = "both")
```
Aqui tenemos dos opciones: la primera es mantener las varaibles **d3**, **d4** y **d5** porque nos interesean manetenerlas en el modelo. En cambio, el segundo es exlcuirlas. Nosotros decidimos tomar la segunda decición.

A partir del resultado creamos el primer modelo

```{r, collapse = TRUE}
modelo_it1 <- glm(formula = diagnostico ~ d1 + d2 + edad, family = "binomial", 
    data = datos_it1)
summary(modelo_it1)

r2 <- calcular_pseudo_R2(modelo_it1)
r2
```
Todas las variables resultan significativas. El AIC es de `r round(modelo_it1$aic, 2)`, que es levemente mejor al modelo 0. De aquí notamos que:

* Por cada incremento de una unidad en **d1**, los odds de tener un diagnóstico positivo se incrementan en `r  round(exp(.086348) * 100 - 100, 2)`%, manteniendo el resto de variables constantes.
* Por cada incremento de una unidad de **d2**, los odss de tener un diagnóstico positivo se reducen en `r round(100 - exp(-.004163) * 100, 2)`%, manteniendo el resto de variables constantes.
* Por cada incremento de un año en la **edad**, los odds de tener un diagnóstico positivo se incrementan en `r  round(exp(.104027) * 100 - 100, 2)`%, manteniendo el resto de variables constantes.

```{r}
tabla_resumen_modelos <- tabla_resumen_modelos %>% 
  add_row(Nombre = "modeo_it1", AIC = modelo_it1$aic, R2 = r2[1], Observacion = "Primer modelo con selección de variables")
rm(r2)
```

## Puntos Influyentes

Empezamos buscando los puntos influyentes con la distancia_cook

```{r}
puntos_influyentes <- data.frame(d_cook = cooks.distance(modelo_it1)) %>% arrange(-d_cook)
head(puntos_influyentes, n = 15)
```

En general, las distancias son menores a uno por lo que no se consideran influyentes. Sin embargo, analizsamos la observación nro 368 por se la que presta una distancia de cook mucho mayor al resto.

```{r}
datos_it1[368,]
```

Esta observación presenta un valor de d2 muy bajo. 

Vamos a explorar los modelos si excluimos dicha observación.

```{r}
datos_it2 <- datos_it1[-368,]
```

Volvemos a realizar los modelos.

```{r, collapse = TRUE}
modelo_it2 <- glm(diagnostico ~ ., data = datos_it2, family = "binomial")
summary(modelo_it2)

r2 <- calcular_pseudo_R2(modelo_it2)
r2
```

Para este modelo resultan **d1**, **d2** y **edad** significativas.

```{r}
tabla_resumen_modelos <- tabla_resumen_modelos %>% 
  add_row(Nombre = "modelo_it2", AIC = modelo_it2$aic, R2 = r2[1], Observacion = "Modelo todas variables, excluimos observacion 368")
rm(r2)
```

Ahora seleccionamos variables con stepwise

```{r}
step(modelo_it2, direction = "both")
```
Creamos el modelo con los resultados

```{r}
modelo_it3 <- glm(formula = diagnostico ~ d1 + d2 + edad, family = "binomial", data = datos_it2)
summary(modelo_it3)

r2 <- calcular_pseudo_R2(modelo_it3)
r2
```
Se obtiene que todas las variables son significativas. Se observa un AIC de `r round(modelo_it3$aic, 2)`, que es el mejor obtenido hasta ahora. 

  * Por cada incremento de una unidad en **d1**, los odds de tener un diagnóstico postivo incrementan en `r round(exp(0.085258) * 100 - 100, 2)`%, manteniendo el resto de variables constantes.
  * Por cada incremento de una unidad en **d2**, los odds de tener un diagnóstico positivo se reducen en `r round(100 - exp(-0.004821) * 100, 2)`%, manteniendo el resto de variables constantes.
  * Por cada incremento de un año en la **edad**, los odds de tener un diagnóstico positivo se incrementan en `r round(exp(0.104276) * 100 - 100, 2)`% manteniendo el resto de variables constantes.
  
```{r}
tabla_resumen_modelos <- tabla_resumen_modelos %>% 
  add_row(Nombre = "modelo_it3", AIC = modelo_it3$aic, R2 = r2[1], Observacion = "Se selecciono variables")

rm(r2)
```
  
Volvemos a buscar puntos influyentes

```{r}
puntos_influyentes <- data.frame(d_cook = cooks.distance(modelo_it3)) %>% arrange(-d_cook)
head(puntos_influyentes, n = 15)
```

Observamos que ninguna d_cook es mayor a 1 y tampoco que haya algunos puntos más alejados que otros. Por esto, no eleminamos ninguna observación.

Como no se observaron cambios significativos al excluir la observación 368, vamos a seguir el análisis con los datos completos (datos_it1 y modelo_it1).

```{r}
rm(datos_it2)
```

